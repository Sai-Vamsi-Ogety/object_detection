{"cells":[{"cell_type":"code","metadata":{"tags":[]},"source":"!pwd","outputs":[{"name":"stdout","text":"/home/jovyan/work\r\n","output_type":"stream"}]},{"cell_type":"code","metadata":{},"source":"!python --version","outputs":[{"name":"stdout","output_type":"stream","text":"Python 3.7.3\r\n"}]},{"cell_type":"code","metadata":{},"source":"# Start writing your code here...","outputs":[]},{"cell_type":"markdown","source":"##  Object Detection\r\n- Object detection is the act of finding the location of an object in an image\r\n- Image classification labels the image as a whole. Finding the position of the object in addition to labeling the object is called object localization. \r\n- Typically, the position of the object is defined by rectangular coordinates. \r\n- Finding multiple objects in the image with rectangular coordinates is called detection.\r\n![Object Detection](https://upload.wikimedia.org/wikipedia/commons/3/38/Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg)\r\n\r\n### Datasets for Object Detection:\r\n- ImageNet\r\n- PASCAL VOC\r\n- COCO\r\n\r\n### Metrics used to evaluatet these Datasets:\r\n- Intersection over Union (IoU) : The IoU is the ratio of the overlapping area of ground truth and predicted area to the total area\r\n- Mean Precision Average (mAP) : The mAP metric is the product of precision and recall of the detected bounding boxes. The mAP value ranges from 0 to 100. The higher the number, the better it is.\r\n\r\n### Approaches :\r\n## Object Detection as Regression :\r\n\r\n![](Images/reg.JPG)\r\n\r\n## Object Detection as classification(Sliding Window) :\r\n\r\n![](Images/slid.JPG)\r\n\r\n## Region Proposal :\r\n\r\n![](Images/regpro.JPG)\r\n\r\n## Family of R-CNN Methods (Region Based Methods for Object Detection):\r\n\r\n### 1. Regions of the convolutional neural network (R-CNN) :\r\n\r\n- The first work in this series was regions for CNNs proposed by Girshick et al.(https://arxiv.org/pdf/1311.2524.pdf) . \r\n- It proposes a few boxes and checks whether any of the boxes correspond to the ground truth. Selective search was used for these region proposals. \r\n- Selective search proposes the regions by grouping the color/texture of windows of various sizes. The selective search looks for blob-like structures. \r\n- It starts with a pixel and produces a blob at a higher scale. It produces around 2,000 region proposals. \r\n- This region proposal is less when compared to all the sliding windows possible.\r\n\r\n## Step 1 :\r\n\r\n![](Images/rcnn1.JPG)\r\n\r\n## Step 2:\r\n\r\n![](Images/rcnn2.JPG)\r\n\r\n## Step 3:\r\n\r\n![](Images/rcnn3.JPG)\r\n\r\n## Step 4:\r\n\r\n![](Images/rcnn4.JPG)\r\n\r\n## Step 5:\r\n\r\n![](Images/rcnn5.JPG)\r\n\r\n## Step 6:\r\n\r\n![](Images/rcnn6.JPG)\r\n\r\n## Problems with R-CNN :\r\n- Training is slow (84h), takes a lot of disk space\r\n- Inference (detection) is slow 47s / image with VGG16 [Simonyan & Zisserman. ICLR15]\r\n\r\n--- \r\n### 2. Fast R-CNN :\r\n\r\n## Step 1: \r\n\r\n![](Images/frcnn1.JPG)\r\n\r\n## Step 2: \r\n\r\n![](Images/frcnn2.JPG)\r\n\r\n## Step 3: \r\n\r\n![](Images/frcnn3.JPG)\r\n\r\n## Step 4: \r\n\r\n![](Images/frcnn4.JPG)\r\n\r\n## Results: \r\n\r\n![](Images/frcnn5.JPG)\r\n\r\n---\r\n### 3. Faster R-CNN:\r\n\r\n## Step 1: We learn to predict those Region Proposals than passing through traditional algorithm\r\n\r\n![](Images/frcnn1.JPG)\r\n\r\n## Result :\r\n\r\n![](Images/frcnn2.JPG)\r\n\r\n--- \r\n## Non-Region based methods or Detection without Proposals :\r\n\r\n- One of the characterestics of this method is that there is no per region processing like the one that happens in Region based methods but rather \r\nthe processing happens on the entire image from start to end. And this sorts of improves speed a lot.\r\n\r\n### YOLO (You Only Look Once) / SSD (Single Shot Detection) :\r\n\r\n![](Images/yolo1.JPG)\r\n\r\n### Hyperparamters :\r\n\r\n![](Images/yolo2.JPG)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## New markdown cell","metadata":{"tags":[]}}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"deepnote_execution_queue":[]}}